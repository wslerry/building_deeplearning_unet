{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] You are using CPU - it might slow and break your program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from data_loader import BasicDataset, RemoteSensingDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch_utils import select_device\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_availble() else \"cpu\"\n",
    "device_option = 'cuda:0'\n",
    "device = select_device(device='cpu' if torch.cuda.is_available() is False else device_option)\n",
    "logging.info(f'You are using {device}')\n",
    "\n",
    "dir_img = Path(r'./data_for_training2/images/')\n",
    "dir_mask = Path(r'./data_for_training2/labels/')\n",
    "img_scale : float = 0.50\n",
    "\n",
    "\n",
    "# 1. Create dataset\n",
    "try:\n",
    "    dataset = RemoteSensingDataset(dir_img, dir_mask, img_scale)\n",
    "except (AssertionError, RuntimeError):\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.cuda.profiler as profiler \n",
    "# import pyprof \n",
    "# pyprof.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split into train / validation partitions\n",
    "n_val = int(len(dataset) * 0.15)\n",
    "n_train = len(dataset) - n_val\n",
    "\n",
    "print(n_val, n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = random_split(dataset,[n_train, n_val])\n",
    "\n",
    "print(train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create data loaders\n",
    "loader_args = dict(batch_size=32, num_workers=8, pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# # (Initialize logging)\n",
    "# experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "# experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "#                               val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "#                                   amp=amp))\n",
    "\n",
    "# logging.info(f'''Starting training:\n",
    "#              Epochs:          {epochs}\n",
    "#              Batch size:      {batch_size}\n",
    "#              Learning rate:   {learning_rate}\n",
    "#              Training size:   {n_train}\n",
    "#              Validation size: {n_val}\n",
    "#              Checkpoints:     {save_checkpoint}\n",
    "#              Device:          {device.type}\n",
    "#              Images scaling:  {img_scale}\n",
    "#              Mixed Precision: {amp}\n",
    "#              ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "global_step = 0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ee7765acde157d0553d062bf8a3e932bd58abec0090ecc73906b90319e40bff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('arcgispro-py3': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
